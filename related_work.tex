In this section, we overview related works and research contributions focusing on serverless computing and model optimization. 

With respect to serverless architecture, the benefit and drawback of such has been well researched by~\cite{ref:onesteptwostep}, in which the authors conduct a case study to show Lambda function can be more expensive than EC2 instances.~\cite{ref:baldini2017} points out serveral open research questions, including the boundaries and statelessness of serverless. Furthermore, we were inspired by ~\cite{ref:matrix} to experiment on disproportional CPU power with matrix multiplication application.  

On the tooling of serverless, the serverless framework~\cite{ref:serverless_framework} contributes on automated packaging and deployment of serverless function on multi-cloud circumstance. Serverless framework uses Cloudformation~\cite{ref:cloudformation} to package and deploy lambda function that generate additional cost, whereas Seneca uses local docker container with no extra cost. Cloud infrastructure provisioning framework terraform~\cite{ref:terraform} also provides automated deployment to serverless platform, but it can not simulate the AWS Lamdba runtime to create deployment package. In addition, AWS CodeDeploy~\cite{ref:codedeploy} serves as component in the continuous Integration and delivery pipeline for serverless architecture, but it again generates extra cost.

Automated hyperparameter optimization has been researched and developed in numerous projects. Google Vizier~\cite{ref:vizier} provides a service of black-box optimization. Optunity~\cite{ref:claesen2014hyperparameter} proposes a Python library for hyperparameter tuning. This could be considered as precursory work of Hyperopt~\cite{ref:hyperopt}, which is a more advanced Python library for serial and parallel hyperparameter optimization over awkward search space. Hyperas ~\cite{ref:hyperas} adds another abstraction layer to hyperopt and facilitates the hyperparameter tuning for Keras ~\cite{ref:keras}. However, none of above work ports hyperparameter tuning tasks to serverless platform and evaluates the tuning performance, cost and latency. To the best of our knowledge, Seneca is the first framework contributing in this aspect.